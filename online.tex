
In this section, we describe online adaptations of the algorithms above and their application 
to search with limited resources (time and memory). 

\subsection{Iterative Deepening Backward Induction Algorithms} \label{sec:idbi}

Minimax search~\cite{AIbook} has been used with much success in sequential perfect information games, 
leading to superhuman strength in computer chess game play, one of the key advances of artifical 
intelligence. 
Minimax search is an online application of backward induction run on approximated game. 
The game is approximated by searching to a fixed depth limit $d$, treating the states at depth $d$
as terminal states, evaluating their values using a heuristic evaluation function, $v(s)$. 
The main focus is to compute an optimal strategy for this heuristic approximation of the true game. 

Under limited time settings, a search algorithm is given a fixed time budget to compute a strategy. 
Since it is difficult to predict in advance the highest depth that can run in the alotted time, 
{\it interative deepening} is employed~\cite{Marsland83}. The main idea is to run several depth-limited 
minimax searches, starting at a low depth and iterativel increasing the depth of each successive search. 
In sequential perfect information games, several enhancements can applied due to researching the same 
nodes, most of which are not immediately applicable in simultaneous move games. However, whether new 
enhancements can be defined for this class of games remains an open research question. 

In our search experiments, we use a depth-limited online version of Algorithm \ref{alg:doab}. To the 
best of our knowledge, this is the first time that depth-limited backward induction has been used for 
online search in simultaneous move games. 






